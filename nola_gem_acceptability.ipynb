{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pzgKP4GEalxQ"
   },
   "source": [
    "## Acceptability, feasibility, and user experiences of NOLA Gem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xRMega9UavJZ"
   },
   "source": [
    "_WIP - NOT FOR DISTRIBUTION_\n",
    "\n",
    "_Vizualization scripts for pilot trial ($N$ = 32) analyses of acceptability, feasibility, and user experience with [NOLA Gem](https://www.researchprotocols.org/2023/1/e47151/authors): a geospatially customizable culturally tailored JITAI for violence-affected people living with HIV._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T5O-o5plbL4_"
   },
   "source": [
    "> `nola_gem_acceptability.ipynb`<br>\n",
    "> Simone J. Skeen (06-16-2025)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DrrkzGPlbaaQ"
   },
   "source": [
    "### 1. Prepare\n",
    "Installs, imports, requisite packages; customizes outputs.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------------------------#\n",
    "\n",
    "#debiug debug debug - force reinstall\n",
    "\n",
    "#!pip uninstall -y scikit-learn scipy numpy\n",
    "#!pip install numpy\n",
    "#!pip install scipy scikit-learn\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "print(\"numpy:\", np.__version__)\n",
    "print(\"scipy:\", scipy.__version__)\n",
    "\n",
    "#-------------------------------------------------------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------------------------#\n",
    "\n",
    "#debug debug debug - rogue numpy installation check\n",
    "\n",
    "import numpy\n",
    "print(numpy.__file__)\n",
    "#print(numpy.__version__)\n",
    "\n",
    "\n",
    "#-------------------------------------------------------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gu7SLsTr09uq",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "!pip install ollama\n",
    "#!pip install python-docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "atjpV2bUbhzM"
   },
   "outputs": [],
   "source": [
    "import matplotlib.font_manager as fm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mticker\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "#import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "#from irrCAC.raw import CAC\n",
    "#from google.colab import drive\n",
    "#from langchain_community.llms import Ollama\n",
    "from matplotlib import cm\n",
    "from matplotlib.lines import Line2D\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "\n",
    "pd.options.mode.copy_on_write = True\n",
    "\n",
    "pd.set_option(\n",
    "    'display.max_columns',\n",
    "    None,\n",
    "    )\n",
    "\n",
    "pd.set_option(\n",
    "    'display.max_rows',\n",
    "    None,\n",
    "    )\n",
    "\n",
    "#warnings.simplefilter(\n",
    "#    action = 'ignore',\n",
    "#    category = FutureWarning,\n",
    "#    )\n",
    "\n",
    "for c in (FutureWarning, UserWarning):\n",
    "    warnings.simplefilter(\n",
    "        action = 'ignore',\n",
    "        category = c,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lJHePSXTcFyM"
   },
   "outputs": [],
   "source": [
    "#fm.fontManager.ttflist += fm.createFontList(['Arial.ttf'])\n",
    "\n",
    "fm.fontManager.addfont('/content/drive/MyDrive/Colab/Arial.ttf')\n",
    "plt.rcParams['font.family'] = 'Arial'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LnpjLWe01Pb-"
   },
   "source": [
    "**Ollama**<br>\n",
    "http://localhost:11434/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mount gdrive (cloud)\n",
    "\n",
    "drive.mount(\n",
    "    '/content/drive',\n",
    "    force_remount = True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Jupyter Lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set wd (local)\n",
    "\n",
    "wd = 'C:/Users/sskee/OneDrive/Documents/02_tulane/01_research/nola_gem/dissem/skeen,etal_acceptability/code'\n",
    "os.chdir(wd)\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4oAjZy230Hbg"
   },
   "source": [
    "### 2. Write\n",
    "Defines `qualitative.py` module.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile qualitative.py\n",
    "\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "def code_texts_deductively_ollama(df, alias, text_column, endpoint_url, prompt_template, model_name):\n",
    "    '''\n",
    "    Classifies each row of 'text' column in provided df in accord with human-specified prompt,\n",
    "    includes chain-of-thought reasoning, returning explanations for classification decision.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        df containing the text to classify.\n",
    "    alias : str\n",
    "        alias (for brevity) of the qualitative code to be applied.\n",
    "    text_column : str\n",
    "        column name in df containing the text to be analyzed.\n",
    "    endpoint_url : str\n",
    "        URL where locally hosted LLM runs.\n",
    "    prompt_template : str\n",
    "        prompt text with a placeholder (e.g. '{text}') where the row's text will be inserted.\n",
    "    model_name : str\n",
    "        model tasked with qualitative deductive coding.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "   df : pd.DataFrame\n",
    "        The original df with two new columns per deductive code: '{alias}_llm' (either \"0\" or \"1\")\n",
    "        and '{alias}_expl' (the cahin-of-thought explanation)\n",
    "    '''\n",
    "\n",
    "    label_column = f'{alias}_llm'\n",
    "    explanation_column = f'{alias}_expl'\n",
    "\n",
    "    # insert cols - necessary for .update() downstream\n",
    "    \n",
    "    df[label_column] = None\n",
    "    df[explanation_column] = None    \n",
    "    \n",
    "    results = []\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        row_text = row[text_column]\n",
    "\n",
    "        unique_id = f\"[Row ID: {idx}]\"\n",
    "        prompt = f\"{unique_id}\\n\\n\" + prompt_template.format(text = row_text)\n",
    "\n",
    "        response = requests.post(\n",
    "            endpoint_url,\n",
    "            headers = {'Content-Type': 'application/json'},\n",
    "            json = {\n",
    "                'model': model_name,\n",
    "                'prompt': prompt,\n",
    "                'stream': False\n",
    "            })\n",
    "\n",
    "        print(f\"\\n--- Index {idx} ---\")\n",
    "        print(\"Prompt:\")\n",
    "        print(prompt)\n",
    "        print(f\"Status: {response.status_code}\")\n",
    "        print(\"Raw response:\")\n",
    "        print(response.text)\n",
    "\n",
    "        label = None\n",
    "        explanation = None\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            try:\n",
    "                result_json = response.json()\n",
    "                raw_response_str = result_json.get('response', ' ')\n",
    "\n",
    "                cleaned_str = raw_response_str.strip().replace(\"```json\", \" \").replace(\"```\", \" \").strip()\n",
    "                parsed_output = json.loads(cleaned_str)\n",
    "\n",
    "                label = parsed_output.get(label_column)\n",
    "                explanation = parsed_output.get(explanation_column)\n",
    "\n",
    "            except (json.JSONDecodeError, KeyError, TypeError) as e:\n",
    "                print(\"JSON error:\", e)\n",
    "                print(\"Bad string:\")\n",
    "                print(cleaned_str)\n",
    "\n",
    "        # save results by row index for correct matching\n",
    "        \n",
    "        results.append({\n",
    "            'idx': idx,\n",
    "            label_column: label,\n",
    "            explanation_column: explanation\n",
    "            })\n",
    "\n",
    "        # impose delay - avoid model caching errors\n",
    "        \n",
    "        time.sleep(0.25)        \n",
    "        \n",
    "    # create result df - align to input df by row index\n",
    "    \n",
    "    result_df = pd.DataFrame(results).set_index('idx')\n",
    "    df.update(result_df)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd\n",
    "from qualitative import(\n",
    "    code_texts_deductively_ollama,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5HMbHCX0cRbR",
    "tags": []
   },
   "source": [
    "### 3. Visualize\n",
    "Plots acceptability, usability, etc. findings.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q5WLb04Ycg0-",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%cd /content/drive/My Drive/Colab/nola_gem_acceptability/inputs/data\n",
    "\n",
    "d = pd.read_csv(\n",
    "    'nola_gem_acceptability_no_loc_tx.csv',\n",
    "    index_col = [0],\n",
    "    )\n",
    "\n",
    "d.info()\n",
    "d.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pz8ZAe2_1B_W"
   },
   "outputs": [],
   "source": [
    "d[[\n",
    "    'intervention1_rev',\n",
    "    'intervention2_rev',\n",
    "    'intervention3_rev',\n",
    "    'intervention4_rev',\n",
    "    'intervention5_rev',\n",
    "    ]].head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "njFUb27COdCd"
   },
   "outputs": [],
   "source": [
    "%cd ../../outputs/figures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RS6CgqU2RO4r",
    "tags": []
   },
   "source": [
    "##### **Fig. 1.** NOLA Gem acceptability: domain general."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H40cGAdiz-36"
   },
   "outputs": [],
   "source": [
    "# aesthetics\n",
    "\n",
    "sns.set_style(\n",
    "    style = 'whitegrid',\n",
    "    rc = None,\n",
    "    )\n",
    "\n",
    "int_cols = [\n",
    "    'intervention1_rev',\n",
    "    'intervention2_rev',\n",
    "    'intervention3_rev',\n",
    "    'intervention4_rev',\n",
    "    'intervention5_rev',\n",
    "    ]\n",
    "\n",
    "# customize x-axis labels\n",
    "\n",
    "x_positions = range(len(int_cols))\n",
    "x_labels = [\n",
    "    'useful',\n",
    "    'easy to understand',\n",
    "    'satisfactory',\n",
    "    'likeable',\n",
    "    'visually appealing',\n",
    "    ]\n",
    "\n",
    "# customize y-axis labels\n",
    "\n",
    "y_labels = {\n",
    "    1: 'disagree',\n",
    "    2: 'somewhat\\ndisagree',\n",
    "    3: 'somewhat\\nagree',\n",
    "    4: 'agree',\n",
    "    }\n",
    "\n",
    "# assign unique colors using a colormap\n",
    "\n",
    "#cmap = cm.get_cmap('Set2', len(int_cols))\n",
    "#colors = [cmap(i) for i in range(len(int_cols))]\n",
    "\n",
    "# assign custom colors via hex: \"Retro Metro\" https://www.heavy.ai/blog/12-color-palettes-for-telling-better-stories-with-your-data\n",
    "\n",
    "#custom_colors = {\n",
    "#    'intervention1_rev': '#b33dc6',\n",
    "#    'intervention2_rev': '#27aeef',\n",
    "#    'intervention3_rev': '#87bc45',\n",
    "#    'intervention4_rev': '#f46a9b',\n",
    "#    'intervention5_rev': '#ef9b20',\n",
    "#    }\n",
    "\n",
    "# uniform color: ng_blue\n",
    "\n",
    "ng_blue = '#7eb0d5'\n",
    "\n",
    "# plot\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "\n",
    "# loop over int1-int5\n",
    "\n",
    "for i, col in enumerate(int_cols):\n",
    "    y_vals = d[col].astype(float) ### coerce numeric\n",
    "    x_jittered = np.random.normal(\n",
    "        loc = i,\n",
    "        scale = 0.16, ### inject jitter\n",
    "        size = len(y_vals),\n",
    "        )\n",
    "\n",
    "#    color = custom_colors[col]\n",
    "\n",
    "    ax.scatter(\n",
    "        x_jittered,\n",
    "        y_vals,\n",
    "        alpha = 0.6,\n",
    "        s = 35,\n",
    "        color = ng_blue,\n",
    "        #edgecolors = 'k',\n",
    "        linewidths = 0.5,\n",
    "        label = col,\n",
    "        )\n",
    "\n",
    "    # overlay mean (SD) by int*\n",
    "\n",
    "    mean_val = y_vals.mean()\n",
    "    std_val = y_vals.std()\n",
    "\n",
    "    ax.errorbar(\n",
    "        i,\n",
    "        mean_val,\n",
    "        yerr = std_val,\n",
    "        fmt = 'D',\n",
    "        color = ng_blue,\n",
    "        #edgecolors = 'k',\n",
    "        markersize = 8,\n",
    "        capsize = 0,\n",
    "        linewidth = 1,\n",
    "        zorder = 3, ### mean (SD) to front\n",
    "        )\n",
    "\n",
    "# format\n",
    "\n",
    "ax.set_xticks(x_positions)\n",
    "ax.set_xticklabels(\n",
    "    x_labels,\n",
    "    rotation = 45,\n",
    "    ha = 'right',\n",
    "    fontsize = 9,\n",
    "    )\n",
    "\n",
    "#ax.set_yticks(list(y_labels.keys()))\n",
    "#ax.set_yticklabels(\n",
    "#    list(y_labels.values()),\n",
    "#    fontsize = 9,\n",
    "#    )\n",
    "\n",
    "# transpose y-axis labels\n",
    "\n",
    "# hide left y-axis ticks and labels\n",
    "\n",
    "ax.tick_params(\n",
    "    axis = 'y',\n",
    "    left = False,\n",
    "    labelleft = False,\n",
    "    )\n",
    "\n",
    "# create a twin y-axis on the right\n",
    "\n",
    "ax_right = ax.secondary_yaxis('right')\n",
    "ax_right.set_yticks(list(y_labels.keys()))\n",
    "ax_right.set_yticklabels(list(y_labels.values()))\n",
    "\n",
    "#ax.set_ylabel(\"rating (1–4)\")\n",
    "#ax.set_xlabel(\n",
    "#    \"I found NOLA Gem to be...\",\n",
    "#    fontsize = 10,\n",
    "#    )\n",
    "\n",
    "ax.set_title(\n",
    "    \"I found NOLA Gem to be...\",\n",
    "    fontsize = 10,\n",
    "    )\n",
    "\n",
    "#ax.grid(\n",
    "#    True,\n",
    "#    axis = 'y',\n",
    "#    linestyle = '--',\n",
    "#    alpha = 0.5,\n",
    "#    )\n",
    "\n",
    "ax.grid(False)\n",
    "plt.tight_layout()\n",
    "\n",
    "# save\n",
    "\n",
    "#plt.savefig(\n",
    "#    'int1_int5_low_res_scatter.png',\n",
    "#    dpi = 100,\n",
    "#    )\n",
    "\n",
    "plt.savefig(\n",
    "    'int1_int5_high_res_scatter.png',\n",
    "    dpi = 300,\n",
    "    )\n",
    "\n",
    "# display\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qqc5gKR0Rfot",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### **Fig. 2a.** NOLA Gem acceptability: perceived helpfulness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n9DVwG1e1Xg1"
   },
   "outputs": [],
   "source": [
    "# aesthetics\n",
    "\n",
    "sns.set_style(\n",
    "    style = 'whitegrid',\n",
    "    rc = None,\n",
    "    )\n",
    "\n",
    "int_cols = [\n",
    "    'intervention6_rev',\n",
    "    'intervention7_rev',\n",
    "    'intervention8_rev',\n",
    "    'intervention9_rev',\n",
    "    'intervention10_rev',\n",
    "    ]\n",
    "\n",
    "# customize x-axis labels\n",
    "\n",
    "x_positions = range(len(int_cols))\n",
    "x_labels = [\n",
    "    'reducing distress',\n",
    "    'improving mood',\n",
    "    'facilitating coping',\n",
    "    'changing habits',\n",
    "    'learning new skills',\n",
    "    ]\n",
    "\n",
    "# customize y-axis labels\n",
    "\n",
    "y_labels = {\n",
    "    1: 'disagree',\n",
    "    2: 'somewhat\\ndisagree',\n",
    "    3: 'somewhat\\nagree',\n",
    "    4: 'agree',\n",
    "    }\n",
    "\n",
    "# assign unique colors using a colormap\n",
    "\n",
    "#cmap = cm.get_cmap('Set2', len(int_cols))\n",
    "#colors = [cmap(i) for i in range(len(int_cols))]\n",
    "\n",
    "# assign custom colors via hex: \"Dutch Field\" https://www.heavy.ai/blog/12-color-palettes-for-telling-better-stories-with-your-data\n",
    "\n",
    "#custom_colors = {\n",
    "#    'intervention6_rev': '#00bfa0',\n",
    "#    'intervention7_rev': '#b3d4ff',\n",
    "#    'intervention8_rev': '#dc0ab4',\n",
    "#    'intervention9_rev': '#ffa300',\n",
    "#    'intervention10_rev': '#9b19f5',\n",
    "#    }\n",
    "\n",
    "# uniform color: ng_blue\n",
    "\n",
    "ng_blue = '#7eb0d5'\n",
    "\n",
    "# plot\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "\n",
    "# loop over int1-int5\n",
    "\n",
    "for i, col in enumerate(int_cols):\n",
    "    y_vals = d[col].astype(float) ### coerce numeric\n",
    "    x_jittered = np.random.normal(\n",
    "        loc = i,\n",
    "        scale = 0.16, ### inject jitter\n",
    "        size = len(y_vals),\n",
    "        )\n",
    "\n",
    "#    color = custom_colors[col]\n",
    "\n",
    "    ax.scatter(\n",
    "        x_jittered,\n",
    "        y_vals,\n",
    "        alpha = 0.6,\n",
    "        s = 35,\n",
    "        color = ng_blue,\n",
    "        #edgecolors = 'k',\n",
    "        linewidths = 0.5,\n",
    "        label = col,\n",
    "        )\n",
    "\n",
    "    # overlay mean (SD) by int*\n",
    "\n",
    "    mean_val = y_vals.mean()\n",
    "    std_val = y_vals.std()\n",
    "\n",
    "    ax.errorbar(\n",
    "        i,\n",
    "        mean_val,\n",
    "        yerr = std_val,\n",
    "        fmt = 'D',\n",
    "        color = ng_blue,\n",
    "        #edgecolors = 'k',\n",
    "        markersize = 8,\n",
    "        capsize = 0,\n",
    "        linewidth = 1,\n",
    "        zorder = 3, ### mean (SD) to front\n",
    "        )\n",
    "\n",
    "# format\n",
    "\n",
    "ax.set_xticks(x_positions)\n",
    "ax.set_xticklabels(\n",
    "    x_labels,\n",
    "    rotation = 45,\n",
    "    ha = 'right',\n",
    "    fontsize = 9,\n",
    "    )\n",
    "\n",
    "#ax.set_yticks(list(y_labels.keys()))\n",
    "#ax.set_yticklabels(\n",
    "#    list(y_labels.values()),\n",
    "#    fontsize = 9,\n",
    "#    )\n",
    "\n",
    "# transpose y-axis labels\n",
    "\n",
    "# hide left y-axis ticks and labels\n",
    "\n",
    "ax.tick_params(\n",
    "    axis = 'y',\n",
    "    left = False,\n",
    "    labelleft = False,\n",
    "    )\n",
    "\n",
    "# create a twin y-axis on the right\n",
    "\n",
    "ax_right = ax.secondary_yaxis('right')\n",
    "ax_right.set_yticks(list(y_labels.keys()))\n",
    "ax_right.set_yticklabels(list(y_labels.values()))\n",
    "\n",
    "#ax.set_ylabel(\"rating (1–4)\")\n",
    "#ax.set_xlabel(\n",
    "#    \"I found NOLA Gem to be helpful in...\",\n",
    "#    fontsize = 10,\n",
    "#    )\n",
    "\n",
    "ax.set_title(\n",
    "    \"($a.$) I found NOLA Gem to be helpful in...\",\n",
    "    fontsize = 10,\n",
    "    )\n",
    "\n",
    "#ax.grid(\n",
    "#    True,\n",
    "#    axis = 'y',\n",
    "#    linestyle = '--',\n",
    "#    alpha = 0.5,\n",
    "#    )\n",
    "\n",
    "ax.grid(False)\n",
    "plt.tight_layout()\n",
    "\n",
    "# save\n",
    "\n",
    "#plt.savefig(\n",
    "#    'int6_int10_low_res_scatter.png',\n",
    "#    dpi = 100,\n",
    "#    )\n",
    "\n",
    "plt.savefig(\n",
    "    'int6_int10_high_res_scatter.png',\n",
    "    dpi = 300,\n",
    "    )\n",
    "\n",
    "# display\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "drYSb9WIT-fv",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### **Fig. 2b.** NOLA Gem acceptability: perceived helpfulness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1oCbPcu7SpXK"
   },
   "outputs": [],
   "source": [
    "# aesthetics\n",
    "\n",
    "sns.set_style(\n",
    "    style = 'whitegrid',\n",
    "    rc = None,\n",
    "    )\n",
    "\n",
    "int_cols = [\n",
    "    'intervention11_rev',\n",
    "    'intervention12_rev',\n",
    "    'intervention13_rev',\n",
    "    'intervention14_rev',\n",
    "    ]\n",
    "\n",
    "# customize x-axis labels\n",
    "\n",
    "x_positions = range(len(int_cols))\n",
    "x_labels = [\n",
    "    'educational sessions',\n",
    "    'skills practice',\n",
    "    'geofencing alerts',\n",
    "    'daily diary suggested skills',\n",
    "    ]\n",
    "\n",
    "# customize y-axis labels\n",
    "\n",
    "y_labels = {\n",
    "    1: 'not very helpful',\n",
    "    2: 'a little\\nhelpful',\n",
    "    3: 'somewhat\\nhelpful',\n",
    "    4: 'very helpful',\n",
    "    }\n",
    "\n",
    "# assign unique colors using a colormap\n",
    "\n",
    "#cmap = cm.get_cmap('Set2', len(int_cols))\n",
    "#colors = [cmap(i) for i in range(len(int_cols))]\n",
    "\n",
    "# assign custom colors via hex: \"Spring Pastels\" https://www.heavy.ai/blog/12-color-palettes-for-telling-better-stories-with-your-data\n",
    "\n",
    "#custom_colors = {\n",
    "#    'intervention11_rev': '#bd7ebe',\n",
    "#    'intervention12_rev': '#b2e061',\n",
    "#    'intervention13_rev': '#7eb0d5',\n",
    "#    'intervention14_rev': '#fd7f6f',\n",
    "#    }\n",
    "\n",
    "# uniform color: ng_blue\n",
    "\n",
    "ng_blue = '#7eb0d5'\n",
    "\n",
    "# plot\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "\n",
    "# loop over int1-int5\n",
    "\n",
    "for i, col in enumerate(int_cols):\n",
    "    y_vals = d[col].astype(float).replace(5, np.nan).dropna() ### coerce numeric, convert '5' to NaN and drop\n",
    "    x_jittered = np.random.normal(\n",
    "        loc = i,\n",
    "        scale = 0.16, ### inject jitter\n",
    "        size = len(y_vals),\n",
    "        )\n",
    "\n",
    "#    color = custom_colors[col]\n",
    "\n",
    "    ax.scatter(\n",
    "        x_jittered,\n",
    "        y_vals,\n",
    "        alpha = 0.6,\n",
    "        s = 35,\n",
    "        color = ng_blue,\n",
    "        #edgecolors = 'k',\n",
    "        linewidths = 0.5,\n",
    "        label = col,\n",
    "        )\n",
    "\n",
    "    # overlay mean (SD) by int*\n",
    "\n",
    "    mean_val = y_vals.mean()\n",
    "    std_val = y_vals.std()\n",
    "\n",
    "    ax.errorbar(\n",
    "        i,\n",
    "        mean_val,\n",
    "        yerr = std_val,\n",
    "        fmt = 'D',\n",
    "        color = ng_blue,\n",
    "        #edgecolors = 'k',\n",
    "        markersize = 8,\n",
    "        capsize = 0,\n",
    "        linewidth = 1,\n",
    "        zorder = 3, ### mean (SD) to front\n",
    "        )\n",
    "\n",
    "# format\n",
    "\n",
    "ax.set_xticks(x_positions)\n",
    "ax.set_xticklabels(\n",
    "    x_labels,\n",
    "    rotation = 45,\n",
    "    ha = 'right',\n",
    "    fontsize = 9,\n",
    "    )\n",
    "\n",
    "#ax.set_yticks(list(y_labels.keys()))\n",
    "#ax.set_yticklabels(\n",
    "#    list(y_labels.values()),\n",
    "#    fontsize = 9,\n",
    "#    )\n",
    "\n",
    "# transpose y-axis labels\n",
    "\n",
    "# hide left y-axis ticks and labels\n",
    "\n",
    "ax.tick_params(\n",
    "    axis = 'y',\n",
    "    left = False,\n",
    "    labelleft = False,\n",
    "    )\n",
    "\n",
    "# create a twin y-axis on the right\n",
    "\n",
    "ax_right = ax.secondary_yaxis('right')\n",
    "ax_right.set_yticks(list(y_labels.keys()))\n",
    "ax_right.set_yticklabels(list(y_labels.values()))\n",
    "\n",
    "#ax.set_ylabel(\"rating (1–4)\")\n",
    "#ax.set_xlabel(\n",
    "#    \"I found NOLA Gem to be helpful in...\",\n",
    "#    fontsize = 10,\n",
    "#    )\n",
    "\n",
    "ax.set_title(\n",
    "    \"($b.$) I found the NOLA Gem __________ features to be...$^a$\",\n",
    "    fontsize = 10,\n",
    "    )\n",
    "\n",
    "#ax.grid(\n",
    "#    True,\n",
    "#    axis = 'y',\n",
    "#    linestyle = '--',\n",
    "#    alpha = 0.5,\n",
    "#    )\n",
    "\n",
    "ax.grid(False)\n",
    "plt.tight_layout()\n",
    "\n",
    "# save\n",
    "\n",
    "#plt.savefig(\n",
    "#    'int6_int10_low_res_scatter.png',\n",
    "#    dpi = 100,\n",
    "#    )\n",
    "\n",
    "plt.savefig(\n",
    "    'int11_int14_high_res_scatter.png',\n",
    "    dpi = 300,\n",
    "    )\n",
    "\n",
    "# display\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rkx4GpWzzwsq"
   },
   "source": [
    "### 4. Code\n",
    "Applies on-device 8B Llama-human synergistic deductive coding\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GVLRLHlT0yMt"
   },
   "source": [
    "#### Transform qual-ready df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd = 'C:/Users/sskee/OneDrive/Documents/02_tulane/01_research/nola_gem/dissem/skeen,etal_acceptability/data'\n",
    "os.chdir(wd)\n",
    "%pwd\n",
    "\n",
    "d = pd.read_csv(\n",
    "    'nola_gem_acceptability_no_loc_tx.csv',\n",
    "    index_col = [0],\n",
    "    )\n",
    "\n",
    "d.info()\n",
    "d.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V68aDTR51jAR"
   },
   "outputs": [],
   "source": [
    "#cols = d.columns.tolist()\n",
    "#print(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "loTG5glMUaO7"
   },
   "outputs": [],
   "source": [
    "d_qual = d[[\n",
    "    'open1',\n",
    "    'open2',\n",
    "    'open3',\n",
    "    'open4',\n",
    "    ]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AvjqrLzk1zys"
   },
   "outputs": [],
   "source": [
    "# insert qual code / rationale cells\n",
    "\n",
    "d_qual[[\n",
    "    'fctn_sjs', 'fctn_rtnl_sjs', 'lgth_sjs', 'lgth_rtnl_sjs',\n",
    "    'tmng_sjs', 'tmng_rtnl_sjs', 'attn_sjs', 'attn_rtnl_sjs',\n",
    "    'gltc_sjs', 'gltc_rtnl_sjs', 'prfc_sjs', 'prfc_rtnl_sjs',\n",
    "    'ftrs_sjs', 'ftrs_rtnl_sjs', 'strs_sjs', 'strs_rtnl_sjs',\n",
    "    ]] = ' '\n",
    "\n",
    "d_qual.info()\n",
    "d_qual.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L_Y_hMMjFZy2"
   },
   "outputs": [],
   "source": [
    "# transform: long qual format for human/LLM coding\n",
    "\n",
    "# list qual columns\n",
    "\n",
    "qual_cols = [\n",
    "    'open1',\n",
    "    'open2',\n",
    "    'open3',\n",
    "    'open4',\n",
    "    ]\n",
    "\n",
    "# dedicate provisional df per qual column\n",
    "\n",
    "for col in qual_cols:\n",
    "    keep_cols = [c for c in d_qual.columns if c not in qual_cols or c == col]\n",
    "    globals()[f'd_qual_{col}'] = d_qual[keep_cols].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p-47ZRIMFZ4c"
   },
   "outputs": [],
   "source": [
    "# specify 'item' col for long df\n",
    "\n",
    "d_qual_open1['item'] = 'open1'\n",
    "d_qual_open2['item'] = 'open2'\n",
    "d_qual_open3['item'] = 'open3'\n",
    "d_qual_open4['item'] = 'open4'\n",
    "\n",
    "# rename all qual cols: 'text'\n",
    "\n",
    "d_qual_open1 = d_qual_open1.rename(\n",
    "    columns = {'open1': 'text'},\n",
    "    )\n",
    "d_qual_open2 = d_qual_open2.rename(\n",
    "    columns = {'open2': 'text'},\n",
    "    )\n",
    "d_qual_open3 = d_qual_open3.rename(\n",
    "    columns = {'open3': 'text'},\n",
    "    )\n",
    "d_qual_open4 = d_qual_open4.rename(\n",
    "    columns = {'open4': 'text'},\n",
    "    )\n",
    "\n",
    "# concatenate: long df\n",
    "\n",
    "d_qual_long = pd.concat(\n",
    "    [d_qual_open1, d_qual_open2,\n",
    "     d_qual_open3, d_qual_open4],\n",
    "    axis = 0,\n",
    "    ignore_index = False,\n",
    "    )\n",
    "\n",
    "# reorder\n",
    "\n",
    "d_qual_long = d_qual_long.reindex(columns = [\n",
    "    'item', 'text',\n",
    "    'fctn_sjs',\t'fctn_rtnl_sjs', 'lgth_sjs', 'lgth_rtnl_sjs', 'tmng_sjs', 'tmng_rtnl_sjs',\n",
    "    'attn_sjs',\t'attn_rtnl_sjs', 'gltc_sjs', 'gltc_rtnl_sjs',\t'prfc_sjs',\t'prfc_rtnl_sjs',\n",
    "    'ftrs_sjs',\t'ftrs_rtnl_sjs', 'strs_sjs', 'strs_rtnl_sjs',\n",
    "    ])\n",
    "\n",
    "d_qual_long.info()\n",
    "d_qual_long.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WgOS6uZD5hkY"
   },
   "outputs": [],
   "source": [
    "#%pwd\n",
    "%cd ../../inputs/data\n",
    "\n",
    "# export\n",
    "\n",
    "d_qual_long.to_excel('nola_gem_acceptability_qual.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GgbuKac52ALs"
   },
   "source": [
    "#### Formulate deductive coding prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tj4Ruxvd5PCk"
   },
   "outputs": [],
   "source": [
    "role = '''\n",
    "    You are tasked with applying pre-defined qualitative codes to segments of text excerpted \n",
    "    from interviews with users of a mental health app for people living with HIV. \n",
    "    \n",
    "    The app included text-messaged surveys multiple times a day, as well as self-directed sessions \n",
    "    on mindfulness meditation, trauma psychoeducation (etc.), and momentary prompts to engage with \n",
    "    brief coping skills training as needed throughout the day. \n",
    "    \n",
    "    You will be provided a definition, instructions, and \n",
    "    key exemplars of text to guide your coding decisions.\n",
    "    '''\n",
    "\n",
    "text = '''\n",
    "    Text:\n",
    "    {text}\n",
    "    '''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q646xsta2gAD"
   },
   "source": [
    "##### _EMA questionnaire length_ (alias: `lgth`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xiqPgZgM3tzw",
    "outputId": "c065f9c9-8a35-43a9-aa29-e1d0a59a5492",
    "tags": []
   },
   "outputs": [],
   "source": [
    "code = 'EMA questionnaire length'\n",
    "alias = 'lgth'\n",
    "code_def = '''\n",
    "    Describes frustration with text message survey, daily diary, or questionnaire (all refer to the same measure) length. \n",
    "    These frustrations can include aspects such as the number of questions, or the amount of time allotted to complete the \n",
    "    questionnaire, or the nature of the questions administered to participants.\n",
    "    \n",
    "    Frustrations must be directly attributable to the duration of the survey or the time it takes to respond to, specifically\n",
    "    and explicitly. Vague dissatisfaction with the survey does not warrant a 'lgth' = 1. \n",
    "    '''\n",
    "code_ex = '''\n",
    "    - \"The questions they texted you, there was just too many…the questions seemed to ask the same thing over and again\"\n",
    "    - \"The number of questions was too many. It's inconvenient especially if you have typical work and family responsibilities\"\n",
    "    - \"There are so many questions on the survey and they don't give you enough time to finish them all\"\n",
    "    '''\n",
    "\n",
    "# ----------------------------------------------------------------------------------------- #\n",
    "definition = f'''\n",
    "    Definition of \"{code}\": {code_def}.\n",
    "    '''\n",
    "\n",
    "instruction = f'''\n",
    "    You will be provided with a piece of text. For each piece of text:\n",
    "    - If it meets the definition of \"{code},\" output {alias}_llm as \"1\".\n",
    "    - Otherwise, output {alias}_llm as \"0\".\n",
    "    - Also provide a short explanation in exactly two sentences, stored in {alias}_expl.\n",
    "\n",
    "    Please respond in valid JSON with keys \"{alias}_llm\" and \"{alias}_expl\" only.\n",
    "    '''\n",
    "\n",
    "example = f'''\n",
    "    Below are human-validated examples of \"{code}\"\n",
    "\n",
    "    - \"{code_ex}\"\n",
    "    '''\n",
    "# ----------------------------------------------------------------------------------------- #\n",
    "\n",
    "# concatenate prompt as f-string\n",
    "\n",
    "lgth_prompt = f'{role}{definition}{instruction}{text}{example}'\n",
    "print(lgth_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RbOPu9Mi21Kk"
   },
   "source": [
    "##### _EMA prompt timing_ (alias: `tmng`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ePbg6rXo54Fe",
    "tags": []
   },
   "outputs": [],
   "source": [
    "code = 'EMA prompt timing'\n",
    "alias = 'tmng'\n",
    "code_def = '''\n",
    "    Describes frustration with text message survey, daily diary, or questionnaire (all refer to the same measure) timing during the day. \n",
    "    These frustrations can include the questionnaires being sent too early, or too late, or being difficult to fit in due to obligations\n",
    "    such as a full-time job.\n",
    "    \n",
    "    Frustrations must be directly attributable to the timing of the survey delivery, specifically\n",
    "    and explicitly. Vague dissatisfaction with the survey does not warrant a 'tmng' = 1. \n",
    "    '''\n",
    "code_ex = '''\n",
    "    - \"I couldn’t always answer the surveys when they sent them during the day…because I’ve got a full-time job\"\n",
    "    - \"The timing was all wrong. The diaries should come in earlier or later in the day so I can answer without disrupting my schedule\"\n",
    "    - \"The time periods for the text message surveys was unworkable for me. Timing would be better if you could choose yourself\"\n",
    "    '''\n",
    "\n",
    "# ----------------------------------------------------------------------------------------- #\n",
    "definition = f'''\n",
    "    Definition of \"{code}\": {code_def}.\n",
    "    '''\n",
    "\n",
    "instruction = f'''\n",
    "    You will be provided with a piece of text. For each piece of text:\n",
    "    - If it meets the definition of \"{code},\" output {alias}_llm as \"1\".\n",
    "    - Otherwise, output {alias}_llm as \"0\".\n",
    "    - Also provide a short explanation in exactly two sentences, stored in {alias}_expl.\n",
    "\n",
    "    Please respond in valid JSON with keys \"{alias}_llm\" and \"{alias}_expl\" only.\n",
    "    '''\n",
    "\n",
    "example = f'''\n",
    "    Below are human-validated examples of \"{code}\"\n",
    "\n",
    "    - \"{code_ex}\"\n",
    "    '''\n",
    "# ----------------------------------------------------------------------------------------- #\n",
    "\n",
    "# concatenate prompt as f-string\n",
    "\n",
    "tmng_prompt = f'{role}{definition}{instruction}{text}{example}'\n",
    "print(tmng_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U_d1TI-l3Eyk"
   },
   "source": [
    "##### _EMA item attunement_ (alias: `attn`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fzkZLW9U3Dpn"
   },
   "outputs": [],
   "source": [
    "code = 'EMA item attunement'\n",
    "alias = 'attn'\n",
    "code_def = '''\n",
    "    Recounts opinions that text message survey, daily diary, or questionnaire (all refer to the same measure) were inappropriate to \n",
    "    or incongruent with app users’ lived experience, including recommendations for more appropriate questions or question wording.\n",
    "    \n",
    "    The text must refer to the mismatch between item wording and the user's life experience, explicitly and specifically, to\n",
    "    warrant a 'attn' = 1. Mentions of formatting issues such as the survey length or timing, alone, do _not_ warrant a 'attn' = 1\n",
    "    '''\n",
    "code_ex = '''\n",
    "    - \"Not all of the questions made sense to me, or really fit into how I thik about my life\"\n",
    "    - \"The questions felt too vague. I wasn't sure what they meant\"\n",
    "    - \"More questions on prayer and surivival, less about drugs and violence\"\n",
    "    '''\n",
    "\n",
    "# ----------------------------------------------------------------------------------------- #\n",
    "definition = f'''\n",
    "    Definition of \"{code}\": {code_def}.\n",
    "    '''\n",
    "\n",
    "instruction = f'''\n",
    "    You will be provided with a piece of text. For each piece of text:\n",
    "    - If it meets the definition of \"{code},\" output {alias}_llm as \"1\".\n",
    "    - Otherwise, output {alias}_llm as \"0\".\n",
    "    - Also provide a short explanation in exactly two sentences, stored in {alias}_expl.\n",
    "\n",
    "    Please respond in valid JSON with keys \"{alias}_llm\" and \"{alias}_expl\" only.\n",
    "    '''\n",
    "\n",
    "example = f'''\n",
    "    Below are human-validated examples of \"{code}\"\n",
    "\n",
    "    - \"{code_ex}\"\n",
    "    '''\n",
    "# ----------------------------------------------------------------------------------------- #\n",
    "\n",
    "# concatenate prompt as f-string\n",
    "\n",
    "attn_prompt = f'{role}{definition}{instruction}{text}{example}'\n",
    "print(attn_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F7yBt-s_3aLD"
   },
   "source": [
    "##### “_Gotta get those glitches fixed_ [in vivo]” (alias: `gltc`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nTzFuGaG3Dte"
   },
   "outputs": [],
   "source": [
    "code = 'Glitch fixes'\n",
    "alias = 'gltc'\n",
    "code_def = '''\n",
    "    Describes any app (including text message delivery) malfunctions.\n",
    "    '''\n",
    "code_ex = '''\n",
    "    - \"It just froze while I was answering my survey one day\"\n",
    "    - \"I feel like it could be great but it felt too glitchy for now\"\n",
    "    - \"The glitches. I just couldn't deal with the glitches\"\n",
    "    '''\n",
    "\n",
    "# ----------------------------------------------------------------------------------------- #\n",
    "definition = f'''\n",
    "    Definition of \"{code}\": {code_def}.\n",
    "    '''\n",
    "\n",
    "instruction = f'''\n",
    "    You will be provided with a piece of text. For each piece of text:\n",
    "    - If it meets the definition of \"{code},\" output {alias}_llm as \"1\".\n",
    "    - Otherwise, output {alias}_llm as \"0\".\n",
    "    - Also provide a short explanation in exactly two sentences, stored in {alias}_expl.\n",
    "\n",
    "    Please respond in valid JSON with keys \"{alias}_llm\" and \"{alias}_expl\" only.\n",
    "    '''\n",
    "\n",
    "example = f'''\n",
    "    Below are human-validated examples of \"{code}\"\n",
    "\n",
    "    - \"{code_ex}\"\n",
    "    '''\n",
    "# ----------------------------------------------------------------------------------------- #\n",
    "\n",
    "# concatenate prompt as f-string\n",
    "\n",
    "gltc_prompt = f'{role}{definition}{instruction}{text}{example}'\n",
    "print(gltc_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G6pDbOL73zTT"
   },
   "source": [
    "##### \"_This app is perfect_ [in vivo]\" (alias: `prfc`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i081-ElA3Dw-",
    "tags": []
   },
   "outputs": [],
   "source": [
    "code = 'Perfection'\n",
    "alias = 'prfc'\n",
    "code_def = '''\n",
    "    Captures all responses that express satisfaction with the pilot app or reject any suggestions for updated features.\n",
    "    \n",
    "    Positive sentiment towards the app, alone, does _not_ warrant a 'prfc' = 1; statements that nothing needs to be changed \n",
    "\tmust be specific and explicit to warrant a 'prfc' = 1.\n",
    "    '''\n",
    "code_ex = '''\n",
    "    - \"I don't think you need to put in any changes at all\"\n",
    "    - \"There was nothing I didn't like\"\n",
    "    - \"I liked it all\"\n",
    "    '''\n",
    "\n",
    "# ----------------------------------------------------------------------------------------- #\n",
    "definition = f'''\n",
    "    Definition of \"{code}\": {code_def}.\n",
    "    '''\n",
    "\n",
    "instruction = f'''\n",
    "    You will be provided with a piece of text. For each piece of text:\n",
    "    - If it meets the definition of \"{code},\" output {alias}_llm as \"1\".\n",
    "    - Otherwise, output {alias}_llm as \"0\".\n",
    "    - Also provide a short explanation in exactly two sentences, stored in {alias}_expl.\n",
    "\n",
    "    Please respond in valid JSON with keys \"{alias}_llm\" and \"{alias}_expl\" only.\n",
    "    '''\n",
    "\n",
    "example = f'''\n",
    "    Below are human-validated examples of \"{code}\"\n",
    "\n",
    "    - \"{code_ex}\"\n",
    "    '''\n",
    "# ----------------------------------------------------------------------------------------- #\n",
    "\n",
    "# concatenate prompt as f-string\n",
    "\n",
    "prfc_prompt = f'{role}{definition}{instruction}{text}{example}'\n",
    "print(prfc_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tweaks and fresh features (alias: `ftrs`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code = 'Tweaks and fresh features'\n",
    "alias = 'ftrs'\n",
    "code_def = '''\n",
    "    Captures all specific recommendations for alterations to existing app features or expressed wishes for \n",
    "    entirely new features to be added to the app.\n",
    "    \n",
    "    New features must be suggested clearly and specifically to warrant a 'ftrs' = 1; dissatisfaction with \n",
    "    existing features alone does _not_ warrant a 'ftrs' = 1.\n",
    "    '''\n",
    "code_ex = '''\n",
    "    - \"More coping skill should be added\"\n",
    "    - \"I wish it had less text, more multimedia\"\n",
    "    - \"The questions should vbe more personalized use to user to better fit our needs\"\n",
    "    '''\n",
    "\n",
    "# ----------------------------------------------------------------------------------------- #\n",
    "definition = f'''\n",
    "    Definition of \"{code}\": {code_def}.\n",
    "    '''\n",
    "\n",
    "instruction = f'''\n",
    "    You will be provided with a piece of text. For each piece of text:\n",
    "    - If it meets the definition of \"{code},\" output {alias}_llm as \"1\".\n",
    "    - Otherwise, output {alias}_llm as \"0\".\n",
    "    - Also provide a short explanation in exactly two sentences, stored in {alias}_expl.\n",
    "\n",
    "    Please respond in valid JSON with keys \"{alias}_llm\" and \"{alias}_expl\" only.\n",
    "    '''\n",
    "\n",
    "example = f'''\n",
    "    Below are human-validated examples of \"{code}\"\n",
    "\n",
    "    - \"{code_ex}\"\n",
    "    '''\n",
    "# ----------------------------------------------------------------------------------------- #\n",
    "\n",
    "# concatenate prompt as f-string\n",
    "\n",
    "ftrs_prompt = f'{role}{definition}{instruction}{text}{example}'\n",
    "print(ftrs_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XSydTIWx431o"
   },
   "source": [
    "##### “_You seem a little stressed…it will tell you what you can do_ [in vivo]” (alias: `strs`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code = 'JITAI recognition'\n",
    "alias = 'strs'\n",
    "code_def = '''\n",
    "    Captures any expression of appreciation for the app's features being offered when needed throughout the day,\n",
    "    or tailored to particular stressors reported by the user.\n",
    "    \n",
    "    Positive sentiment towards the app, alone, does _not_ warrant a 'strs' = 1; descriptions of the app being uniquely \n",
    "    responsive to users' needs must be specific and explicit to warrant a 'strs' = 1.\n",
    "    '''\n",
    "code_ex = '''\n",
    "    - \"I liked how different meditations were offered for different stresses you mention throughout the day\"\n",
    "    - \"The daily check-ins and quick follow ups to try and help you right when you most need it\"\n",
    "    - \"Learning all these new skills to stay calm and collected during the day\"\n",
    "    '''\n",
    "\n",
    "# ----------------------------------------------------------------------------------------- #\n",
    "definition = f'''\n",
    "    Definition of \"{code}\": {code_def}.\n",
    "    '''\n",
    "\n",
    "instruction = f'''\n",
    "    You will be provided with a piece of text. For each piece of text:\n",
    "    - If it meets the definition of \"{code},\" output {alias}_llm as \"1\".\n",
    "    - Otherwise, output {alias}_llm as \"0\".\n",
    "    - Also provide a short explanation in exactly two sentences, stored in {alias}_expl.\n",
    "\n",
    "    Please respond in valid JSON with keys \"{alias}_llm\" and \"{alias}_expl\" only.\n",
    "    '''\n",
    "\n",
    "example = f'''\n",
    "    Below are human-validated examples of \"{code}\"\n",
    "\n",
    "    - \"{code_ex}\"\n",
    "    '''\n",
    "# ----------------------------------------------------------------------------------------- #\n",
    "\n",
    "# concatenate prompt as f-string\n",
    "\n",
    "strs_prompt = f'{role}{definition}{instruction}{text}{example}'\n",
    "print(strs_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dual-code human-coded qual data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BktZJOY03D0g"
   },
   "outputs": [],
   "source": [
    "#%cd /content/drive/My Drive/Colab/nola_gem_acceptability/inputs/data\n",
    "\n",
    "os.chdir('C:/Users/sskee/OneDrive/Documents/02_tulane/01_research/nola_gem/dissem/skeen,etal_acceptability/data/qual')\n",
    "\n",
    "d = pd.read_excel(\n",
    "    'nola_gem_acceptability_qual_sjs.xlsx',\n",
    "    index_col = [0],\n",
    "    )\n",
    "\n",
    "d.info()\n",
    "d.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cfyU-8J73D3T",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#%%capture\n",
    "\n",
    "# locally hosted Ollama endpoint\n",
    "\n",
    "ollama_endpoint = 'http://localhost:11434/api/generate'\n",
    "\n",
    "# define aliases, prompts\n",
    "\n",
    "prompts = [\n",
    "    ('lgth', lgth_prompt), ### (alias, prompt_template)\n",
    "    ('tmng', tmng_prompt),\n",
    "    ('attn', attn_prompt),\n",
    "    ('gltc', gltc_prompt),\n",
    "    ('prfc', prfc_prompt),\n",
    "    ('ftrs', ftrs_prompt),\n",
    "    ('strs', strs_prompt),\n",
    "    ]\n",
    "\n",
    "# loop through each alias, prompt\n",
    "\n",
    "for alias, prompt_template in prompts:\n",
    "\n",
    "# apply code_texts_deductively_ollama over aliases, prompts, updated_df\n",
    "\n",
    "    d_coded = code_texts_deductively_ollama(\n",
    "        d,\n",
    "        alias = alias,\n",
    "        text_column = 'text',\n",
    "        endpoint_url = ollama_endpoint,\n",
    "        prompt_template = prompt_template,\n",
    "        model_name = 'gemma3:12B',\n",
    "        )\n",
    "\n",
    "d_coded.head(3)\n",
    "\n",
    "# export\n",
    "\n",
    "d_coded.to_excel('d_coded.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute Cohen's $\\kappa$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\sskee\\\\OneDrive\\\\Documents\\\\02_tulane\\\\01_research\\\\nola_gem\\\\dissem\\\\skeen,etal_acceptability\\\\data\\\\qual'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir('C:/Users/sskee/OneDrive/Documents/02_tulane/01_research/nola_gem/dissem/skeen,etal_acceptability/data/qual')\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 88 entries, 1008 to 1051\n",
      "Data columns (total 32 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   item           88 non-null     object \n",
      " 1   text           88 non-null     object \n",
      " 2   fctn_sjs       88 non-null     object \n",
      " 3   fctn_rtnl_sjs  88 non-null     object \n",
      " 4   lgth_sjs       88 non-null     float64\n",
      " 5   lgth_rtnl_sjs  86 non-null     object \n",
      " 6   tmng_sjs       88 non-null     float64\n",
      " 7   tmng_rtnl_sjs  87 non-null     object \n",
      " 8   attn_sjs       88 non-null     float64\n",
      " 9   attn_rtnl_sjs  88 non-null     object \n",
      " 10  gltc_sjs       88 non-null     float64\n",
      " 11  gltc_rtnl_sjs  88 non-null     object \n",
      " 12  prfc_sjs       88 non-null     float64\n",
      " 13  prfc_rtnl_sjs  88 non-null     object \n",
      " 14  ftrs_sjs       88 non-null     float64\n",
      " 15  ftrs_rtnl_sjs  88 non-null     object \n",
      " 16  strs_sjs       88 non-null     float64\n",
      " 17  strs_rtnl_sjs  84 non-null     object \n",
      " 18  lgth_llm       88 non-null     int64  \n",
      " 19  lgth_expl      88 non-null     object \n",
      " 20  tmng_llm       88 non-null     int64  \n",
      " 21  tmng_expl      88 non-null     object \n",
      " 22  attn_llm       88 non-null     int64  \n",
      " 23  attn_expl      88 non-null     object \n",
      " 24  gltc_llm       88 non-null     int64  \n",
      " 25  gltc_expl      88 non-null     object \n",
      " 26  prfc_llm       88 non-null     int64  \n",
      " 27  prfc_expl      88 non-null     object \n",
      " 28  ftrs_llm       88 non-null     int64  \n",
      " 29  ftrs_expl      88 non-null     object \n",
      " 30  strs_llm       88 non-null     int64  \n",
      " 31  strs_expl      88 non-null     object \n",
      "dtypes: float64(7), int64(7), object(18)\n",
      "memory usage: 22.7+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item</th>\n",
       "      <th>text</th>\n",
       "      <th>fctn_sjs</th>\n",
       "      <th>fctn_rtnl_sjs</th>\n",
       "      <th>lgth_sjs</th>\n",
       "      <th>lgth_rtnl_sjs</th>\n",
       "      <th>tmng_sjs</th>\n",
       "      <th>tmng_rtnl_sjs</th>\n",
       "      <th>attn_sjs</th>\n",
       "      <th>attn_rtnl_sjs</th>\n",
       "      <th>gltc_sjs</th>\n",
       "      <th>gltc_rtnl_sjs</th>\n",
       "      <th>prfc_sjs</th>\n",
       "      <th>prfc_rtnl_sjs</th>\n",
       "      <th>ftrs_sjs</th>\n",
       "      <th>ftrs_rtnl_sjs</th>\n",
       "      <th>strs_sjs</th>\n",
       "      <th>strs_rtnl_sjs</th>\n",
       "      <th>lgth_llm</th>\n",
       "      <th>lgth_expl</th>\n",
       "      <th>tmng_llm</th>\n",
       "      <th>tmng_expl</th>\n",
       "      <th>attn_llm</th>\n",
       "      <th>attn_expl</th>\n",
       "      <th>gltc_llm</th>\n",
       "      <th>gltc_expl</th>\n",
       "      <th>prfc_llm</th>\n",
       "      <th>prfc_expl</th>\n",
       "      <th>ftrs_llm</th>\n",
       "      <th>ftrs_expl</th>\n",
       "      <th>strs_llm</th>\n",
       "      <th>strs_expl</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1008</th>\n",
       "      <td>open1</td>\n",
       "      <td>the app shut off - system was down</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>1.0</td>\n",
       "      <td>the app shut off - system was down</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>This text describes a technical issue with the...</td>\n",
       "      <td>0</td>\n",
       "      <td>The text describes a system outage, not a frus...</td>\n",
       "      <td>0</td>\n",
       "      <td>This text describes a technical issue with the...</td>\n",
       "      <td>1</td>\n",
       "      <td>The text describes the app shutting off and th...</td>\n",
       "      <td>0</td>\n",
       "      <td>This text describes a technical issue with the...</td>\n",
       "      <td>0</td>\n",
       "      <td>This text describes a system outage, which is ...</td>\n",
       "      <td>0</td>\n",
       "      <td>The provided text describes a system outage, i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011</th>\n",
       "      <td>open1</td>\n",
       "      <td>Some of the questions asked I really didn't kn...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>1.0</td>\n",
       "      <td>Some of the questions asked I really didn't kn...</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>The provided text expresses difficulty answeri...</td>\n",
       "      <td>0</td>\n",
       "      <td>This text expresses difficulty answering the s...</td>\n",
       "      <td>1</td>\n",
       "      <td>The user explicitly states they didn't know ho...</td>\n",
       "      <td>0</td>\n",
       "      <td>This text describes difficulty answering surve...</td>\n",
       "      <td>0</td>\n",
       "      <td>The text expresses difficulty answering some o...</td>\n",
       "      <td>0</td>\n",
       "      <td>This text expresses difficulty answering surve...</td>\n",
       "      <td>0</td>\n",
       "      <td>This text describes a difficulty with the app'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1014</th>\n",
       "      <td>open1</td>\n",
       "      <td>I didn't really have the time to dive into the...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>The text expresses a general lack of time to e...</td>\n",
       "      <td>1</td>\n",
       "      <td>The user explicitly mentions \"timing\" as the r...</td>\n",
       "      <td>0</td>\n",
       "      <td>The text mentions a lack of time to engage wit...</td>\n",
       "      <td>0</td>\n",
       "      <td>This text discusses timing issues related to t...</td>\n",
       "      <td>0</td>\n",
       "      <td>The user expresses a generally positive sentim...</td>\n",
       "      <td>0</td>\n",
       "      <td>The user expresses a generally positive view o...</td>\n",
       "      <td>0</td>\n",
       "      <td>The user expresses a positive overall impressi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       item                                               text fctn_sjs  \\\n",
       "id                                                                        \n",
       "1008  open1                the app shut off - system was down             \n",
       "1011  open1  Some of the questions asked I really didn't kn...            \n",
       "1014  open1  I didn't really have the time to dive into the...            \n",
       "\n",
       "     fctn_rtnl_sjs  lgth_sjs lgth_rtnl_sjs  tmng_sjs tmng_rtnl_sjs  attn_sjs  \\\n",
       "id                                                                             \n",
       "1008                     0.0                     0.0                     0.0   \n",
       "1011                     0.0                     0.0                     1.0   \n",
       "1014                     0.0                     0.0                     0.0   \n",
       "\n",
       "                                          attn_rtnl_sjs  gltc_sjs  \\\n",
       "id                                                                  \n",
       "1008                                                          1.0   \n",
       "1011  Some of the questions asked I really didn't kn...       0.0   \n",
       "1014                                                          0.0   \n",
       "\n",
       "                             gltc_rtnl_sjs  prfc_sjs prfc_rtnl_sjs  ftrs_sjs  \\\n",
       "id                                                                             \n",
       "1008   the app shut off - system was down        0.0                     0.0   \n",
       "1011                                             0.0                     0.0   \n",
       "1014                                             0.0                     0.0   \n",
       "\n",
       "     ftrs_rtnl_sjs  strs_sjs strs_rtnl_sjs  lgth_llm  \\\n",
       "id                                                     \n",
       "1008                     0.0                       0   \n",
       "1011                     0.0                       0   \n",
       "1014                     0.0                       0   \n",
       "\n",
       "                                              lgth_expl  tmng_llm  \\\n",
       "id                                                                  \n",
       "1008  This text describes a technical issue with the...         0   \n",
       "1011  The provided text expresses difficulty answeri...         0   \n",
       "1014  The text expresses a general lack of time to e...         1   \n",
       "\n",
       "                                              tmng_expl  attn_llm  \\\n",
       "id                                                                  \n",
       "1008  The text describes a system outage, not a frus...         0   \n",
       "1011  This text expresses difficulty answering the s...         1   \n",
       "1014  The user explicitly mentions \"timing\" as the r...         0   \n",
       "\n",
       "                                              attn_expl  gltc_llm  \\\n",
       "id                                                                  \n",
       "1008  This text describes a technical issue with the...         1   \n",
       "1011  The user explicitly states they didn't know ho...         0   \n",
       "1014  The text mentions a lack of time to engage wit...         0   \n",
       "\n",
       "                                              gltc_expl  prfc_llm  \\\n",
       "id                                                                  \n",
       "1008  The text describes the app shutting off and th...         0   \n",
       "1011  This text describes difficulty answering surve...         0   \n",
       "1014  This text discusses timing issues related to t...         0   \n",
       "\n",
       "                                              prfc_expl  ftrs_llm  \\\n",
       "id                                                                  \n",
       "1008  This text describes a technical issue with the...         0   \n",
       "1011  The text expresses difficulty answering some o...         0   \n",
       "1014  The user expresses a generally positive sentim...         0   \n",
       "\n",
       "                                              ftrs_expl  strs_llm  \\\n",
       "id                                                                  \n",
       "1008  This text describes a system outage, which is ...         0   \n",
       "1011  This text expresses difficulty answering surve...         0   \n",
       "1014  The user expresses a generally positive view o...         0   \n",
       "\n",
       "                                              strs_expl  \n",
       "id                                                       \n",
       "1008  The provided text describes a system outage, i...  \n",
       "1011  This text describes a difficulty with the app'...  \n",
       "1014  The user expresses a positive overall impressi...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = pd.read_excel(\n",
    "    'd_coded.xlsx',\n",
    "    index_col = [0],\n",
    "    )\n",
    "\n",
    "encodings_sjs = [\n",
    "    'lgth_sjs', \n",
    "    'tmng_sjs',\n",
    "    'attn_sjs',\n",
    "    'gltc_sjs',\n",
    "    'prfc_sjs',\n",
    "    'ftrs_sjs',\n",
    "    'strs_sjs',\n",
    "    ]\n",
    "\n",
    "# numeric conversion - coerce\n",
    "\n",
    "for e in encodings_sjs:\n",
    "    d[e] = pd.to_numeric(d[e], errors = 'coerce')\n",
    "\n",
    "# replace NaN w/ 0    \n",
    "    \n",
    "d[encodings_sjs] = d[encodings_sjs].fillna(0)\n",
    "\n",
    "# inspect\n",
    "\n",
    "d.info()\n",
    "d.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent agreement for lgth_sjs & lgth_llm: 94.32%\n",
      "Percent agreement for tmng_sjs & tmng_llm: 93.18%\n",
      "Percent agreement for attn_sjs & attn_llm: 94.32%\n",
      "Percent agreement for gltc_sjs & gltc_llm: 100.00%\n",
      "Percent agreement for prfc_sjs & prfc_llm: 96.59%\n",
      "Percent agreement for ftrs_sjs & ftrs_llm: 77.27%\n",
      "Percent agreement for strs_sjs & strs_llm: 92.05%\n",
      "\n",
      "\n",
      "Cohen's Kappa for lgth_sjs and lgth_llm: 0.64\n",
      "Cohen's Kappa for tmng_sjs and tmng_llm: 0.63\n",
      "Cohen's Kappa for attn_sjs and attn_llm: 0.68\n",
      "Cohen's Kappa for gltc_sjs and gltc_llm: 1.00\n",
      "Cohen's Kappa for prfc_sjs and prfc_llm: 0.89\n",
      "Cohen's Kappa for ftrs_sjs and ftrs_llm: 0.23\n",
      "Cohen's Kappa for strs_sjs and strs_llm: 0.49\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# define kappa fx\n",
    "\n",
    "def calculate_kappa(d, col1, col2):\n",
    "    return cohen_kappa_score(d[col1], d[col2])\n",
    "\n",
    "col_pairs = [\n",
    "    ('lgth_sjs', 'lgth_llm'), \n",
    "    ('tmng_sjs', 'tmng_llm'),\n",
    "    ('attn_sjs', 'attn_llm'),\n",
    "    ('gltc_sjs', 'gltc_llm'),\n",
    "    ('prfc_sjs', 'prfc_llm'),\n",
    "    ('ftrs_sjs', 'ftrs_llm'),\n",
    "    ('strs_sjs', 'strs_llm'),\n",
    "    ]\n",
    "\n",
    "# initialize dict\n",
    "\n",
    "kappa_results = {}\n",
    "\n",
    "# % agreement loop\n",
    "\n",
    "def calculate_percent_agreement(df, col_pairs):\n",
    "    results = {}\n",
    "    for col1, col2 in col_pairs:\n",
    "        agreement = df[col1] == df[col2]\n",
    "        percent_agreement = (agreement.sum() / len(df)) * 100\n",
    "        results[f\"{col1} & {col2}\"] = percent_agreement\n",
    "    return results\n",
    "\n",
    "percent_agreement_results = calculate_percent_agreement(d, col_pairs)\n",
    "\n",
    "for pair, percent in percent_agreement_results.items():\n",
    "    print(f\"Percent agreement for {pair}: {percent:.2f}%\")\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "# kappa loop\n",
    "\n",
    "for col1, col2 in col_pairs:\n",
    "    kappa = calculate_kappa(d, col1, col2)\n",
    "    kappa_results[f'{col1} and {col2}'] = kappa\n",
    "\n",
    "for pair, kappa in kappa_results.items():\n",
    "    print(f\"Cohen's Kappa for {pair}: {kappa:.2f}\")\n",
    "    \n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### _drop `ftrs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = d.drop(columns=[col for col in d.columns if col.startswith(('ftrs_', 'fctn_'))]) ### drop 'fctn_' cols - superordinate theme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Flag disagreements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(d.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 88 entries, 1008 to 1051\n",
      "Data columns (total 32 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   item           88 non-null     object \n",
      " 1   text           88 non-null     object \n",
      " 2   lgth_sjs       88 non-null     float64\n",
      " 3   lgth_rtnl_sjs  86 non-null     object \n",
      " 4   lgth_llm       88 non-null     int64  \n",
      " 5   lgth_expl      88 non-null     object \n",
      " 6   lgth_dis       88 non-null     int64  \n",
      " 7   tmng_sjs       88 non-null     float64\n",
      " 8   tmng_rtnl_sjs  87 non-null     object \n",
      " 9   tmng_llm       88 non-null     int64  \n",
      " 10  tmng_expl      88 non-null     object \n",
      " 11  tmng_dis       88 non-null     int64  \n",
      " 12  attn_sjs       88 non-null     float64\n",
      " 13  attn_rtnl_sjs  88 non-null     object \n",
      " 14  attn_llm       88 non-null     int64  \n",
      " 15  attn_expl      88 non-null     object \n",
      " 16  attn_dis       88 non-null     int64  \n",
      " 17  gltc_sjs       88 non-null     float64\n",
      " 18  gltc_rtnl_sjs  88 non-null     object \n",
      " 19  gltc_llm       88 non-null     int64  \n",
      " 20  gltc_expl      88 non-null     object \n",
      " 21  gltc_dis       88 non-null     int64  \n",
      " 22  prfc_sjs       88 non-null     float64\n",
      " 23  prfc_rtnl_sjs  88 non-null     object \n",
      " 24  prfc_llm       88 non-null     int64  \n",
      " 25  prfc_expl      88 non-null     object \n",
      " 26  prfc_dis       88 non-null     int64  \n",
      " 27  strs_sjs       88 non-null     float64\n",
      " 28  strs_rtnl_sjs  84 non-null     object \n",
      " 29  strs_llm       88 non-null     int64  \n",
      " 30  strs_expl      88 non-null     object \n",
      " 31  strs_dis       88 non-null     int64  \n",
      "dtypes: float64(6), int64(12), object(14)\n",
      "memory usage: 22.7+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item</th>\n",
       "      <th>text</th>\n",
       "      <th>lgth_sjs</th>\n",
       "      <th>lgth_rtnl_sjs</th>\n",
       "      <th>lgth_llm</th>\n",
       "      <th>lgth_expl</th>\n",
       "      <th>lgth_dis</th>\n",
       "      <th>tmng_sjs</th>\n",
       "      <th>tmng_rtnl_sjs</th>\n",
       "      <th>tmng_llm</th>\n",
       "      <th>tmng_expl</th>\n",
       "      <th>tmng_dis</th>\n",
       "      <th>attn_sjs</th>\n",
       "      <th>attn_rtnl_sjs</th>\n",
       "      <th>attn_llm</th>\n",
       "      <th>attn_expl</th>\n",
       "      <th>attn_dis</th>\n",
       "      <th>gltc_sjs</th>\n",
       "      <th>gltc_rtnl_sjs</th>\n",
       "      <th>gltc_llm</th>\n",
       "      <th>gltc_expl</th>\n",
       "      <th>gltc_dis</th>\n",
       "      <th>prfc_sjs</th>\n",
       "      <th>prfc_rtnl_sjs</th>\n",
       "      <th>prfc_llm</th>\n",
       "      <th>prfc_expl</th>\n",
       "      <th>prfc_dis</th>\n",
       "      <th>strs_sjs</th>\n",
       "      <th>strs_rtnl_sjs</th>\n",
       "      <th>strs_llm</th>\n",
       "      <th>strs_expl</th>\n",
       "      <th>strs_dis</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1008</th>\n",
       "      <td>open1</td>\n",
       "      <td>the app shut off - system was down</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>This text describes a technical issue with the...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>The text describes a system outage, not a frus...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>This text describes a technical issue with the...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>the app shut off - system was down</td>\n",
       "      <td>1</td>\n",
       "      <td>The text describes the app shutting off and th...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>This text describes a technical issue with the...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>The provided text describes a system outage, i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011</th>\n",
       "      <td>open1</td>\n",
       "      <td>Some of the questions asked I really didn't kn...</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>The provided text expresses difficulty answeri...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>This text expresses difficulty answering the s...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Some of the questions asked I really didn't kn...</td>\n",
       "      <td>1</td>\n",
       "      <td>The user explicitly states they didn't know ho...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>This text describes difficulty answering surve...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>The text expresses difficulty answering some o...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>This text describes a difficulty with the app'...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1014</th>\n",
       "      <td>open1</td>\n",
       "      <td>I didn't really have the time to dive into the...</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>The text expresses a general lack of time to e...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>The user explicitly mentions \"timing\" as the r...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>The text mentions a lack of time to engage wit...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>This text discusses timing issues related to t...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>The user expresses a generally positive sentim...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>The user expresses a positive overall impressi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       item                                               text  lgth_sjs  \\\n",
       "id                                                                         \n",
       "1008  open1                the app shut off - system was down        0.0   \n",
       "1011  open1  Some of the questions asked I really didn't kn...       0.0   \n",
       "1014  open1  I didn't really have the time to dive into the...       0.0   \n",
       "\n",
       "     lgth_rtnl_sjs  lgth_llm  \\\n",
       "id                             \n",
       "1008                       0   \n",
       "1011                       0   \n",
       "1014                       0   \n",
       "\n",
       "                                              lgth_expl  lgth_dis  tmng_sjs  \\\n",
       "id                                                                            \n",
       "1008  This text describes a technical issue with the...         0       0.0   \n",
       "1011  The provided text expresses difficulty answeri...         0       0.0   \n",
       "1014  The text expresses a general lack of time to e...         0       0.0   \n",
       "\n",
       "     tmng_rtnl_sjs  tmng_llm  \\\n",
       "id                             \n",
       "1008                       0   \n",
       "1011                       0   \n",
       "1014                       1   \n",
       "\n",
       "                                              tmng_expl  tmng_dis  attn_sjs  \\\n",
       "id                                                                            \n",
       "1008  The text describes a system outage, not a frus...         0       0.0   \n",
       "1011  This text expresses difficulty answering the s...         0       1.0   \n",
       "1014  The user explicitly mentions \"timing\" as the r...         1       0.0   \n",
       "\n",
       "                                          attn_rtnl_sjs  attn_llm  \\\n",
       "id                                                                  \n",
       "1008                                                            0   \n",
       "1011  Some of the questions asked I really didn't kn...         1   \n",
       "1014                                                            0   \n",
       "\n",
       "                                              attn_expl  attn_dis  gltc_sjs  \\\n",
       "id                                                                            \n",
       "1008  This text describes a technical issue with the...         0       1.0   \n",
       "1011  The user explicitly states they didn't know ho...         0       0.0   \n",
       "1014  The text mentions a lack of time to engage wit...         0       0.0   \n",
       "\n",
       "                             gltc_rtnl_sjs  gltc_llm  \\\n",
       "id                                                     \n",
       "1008   the app shut off - system was down          1   \n",
       "1011                                               0   \n",
       "1014                                               0   \n",
       "\n",
       "                                              gltc_expl  gltc_dis  prfc_sjs  \\\n",
       "id                                                                            \n",
       "1008  The text describes the app shutting off and th...         0       0.0   \n",
       "1011  This text describes difficulty answering surve...         0       0.0   \n",
       "1014  This text discusses timing issues related to t...         0       0.0   \n",
       "\n",
       "     prfc_rtnl_sjs  prfc_llm  \\\n",
       "id                             \n",
       "1008                       0   \n",
       "1011                       0   \n",
       "1014                       0   \n",
       "\n",
       "                                              prfc_expl  prfc_dis  strs_sjs  \\\n",
       "id                                                                            \n",
       "1008  This text describes a technical issue with the...         0       0.0   \n",
       "1011  The text expresses difficulty answering some o...         0       0.0   \n",
       "1014  The user expresses a generally positive sentim...         0       0.0   \n",
       "\n",
       "     strs_rtnl_sjs  strs_llm  \\\n",
       "id                             \n",
       "1008                       0   \n",
       "1011                       0   \n",
       "1014                       0   \n",
       "\n",
       "                                              strs_expl  strs_dis  \n",
       "id                                                                 \n",
       "1008  The provided text describes a system outage, i...         0  \n",
       "1011  This text describes a difficulty with the app'...         0  \n",
       "1014  The user expresses a positive overall impressi...         0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# flag disagreements fx\n",
    "\n",
    "def encode_disagreements(row):\n",
    "    return 1 if row[0] != row[1] else 0\n",
    "\n",
    "col_dis = [\n",
    "    ('lgth_sjs', 'lgth_llm', 'lgth_dis'), \n",
    "    ('tmng_sjs', 'tmng_llm', 'tmng_dis'),\n",
    "    ('attn_sjs', 'attn_llm', 'attn_dis'),\n",
    "    ('gltc_sjs', 'gltc_llm', 'gltc_dis'),\n",
    "    ('prfc_sjs', 'prfc_llm', 'prfc_dis'),\n",
    "    ('strs_sjs', 'strs_llm', 'strs_dis'),\n",
    "    ]\n",
    "\n",
    "for col1, col2, dis_col in col_dis:\n",
    "    d[dis_col] = d[[col1, col2]].apply(\n",
    "        encode_disagreements,\n",
    "        axis = 1,\n",
    "        )\n",
    "\n",
    "# obfuscate human vs. Gemma encodings    \n",
    "    \n",
    "# Example: rename _sjs to _a and _llm to _b\n",
    "\n",
    "#d.columns = [\n",
    "#    col.replace('_sjs', '_a').replace('_llm', '_b') if col.endswith(('_sjs', '_llm')) else col\n",
    "#    for col in d.columns\n",
    "#    ]\n",
    "\n",
    "# reorder for ST interpretability \n",
    "\n",
    "d = d[[\n",
    "    'item', 'text', \n",
    "    'lgth_sjs', 'lgth_rtnl_sjs', 'lgth_llm', 'lgth_expl','lgth_dis', \n",
    "    'tmng_sjs', 'tmng_rtnl_sjs', 'tmng_llm', 'tmng_expl', 'tmng_dis', \n",
    "    'attn_sjs', 'attn_rtnl_sjs', 'attn_llm', 'attn_expl', 'attn_dis', \n",
    "    'gltc_sjs', 'gltc_rtnl_sjs','gltc_llm', 'gltc_expl', 'gltc_dis', \n",
    "    'prfc_sjs', 'prfc_rtnl_sjs','prfc_llm', 'prfc_expl', 'prfc_dis', \n",
    "    'strs_sjs', 'strs_rtnl_sjs', 'strs_llm', 'strs_expl', 'strs_dis',\n",
    "    ]]\n",
    "\n",
    "# inspect\n",
    "\n",
    "d.info()\n",
    "d.head(3)    \n",
    "        \n",
    "# export\n",
    "\n",
    "d.to_excel(f'd_coded_icr.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> End of nola_gem_acceptability.ipynb"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "RS6CgqU2RO4r",
    "qqc5gKR0Rfot",
    "drYSb9WIT-fv"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
